{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below defines the ratio of NaNs in the code to the length of the column. If this ratio is greater than given threshold, the column is considered as severely missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of seriously missing values\n",
    "def missing_values(data, threshold):\n",
    "    i=0\n",
    "    names = []\n",
    "    data_length = len(data)\n",
    "    for name in data.columns:\n",
    "        a = ((1-data[name].count()/data_length)*100).astype(int)\n",
    "        if a > threshold:\n",
    "            i+=1\n",
    "            names.append(name)\n",
    "    return(i, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://www.openml.org/data/get_csv/53995/KDDCup09_churn.arff')\n",
    "data = data.replace({\"?\": np.NaN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_columns = missing_values(data,90)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bad_columns:\n",
    "    data_clean[col+\"_na\"] = data_clean[col] == np.NaN\n",
    "    data_clean.drop(col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>...</th>\n",
       "      <th>Var186_na</th>\n",
       "      <th>Var187_na</th>\n",
       "      <th>Var188_na</th>\n",
       "      <th>Var190_na</th>\n",
       "      <th>Var191_na</th>\n",
       "      <th>Var209_na</th>\n",
       "      <th>Var213_na</th>\n",
       "      <th>Var215_na</th>\n",
       "      <th>Var224_na</th>\n",
       "      <th>Var230_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1526</td>\n",
       "      <td>7</td>\n",
       "      <td>184</td>\n",
       "      <td>464</td>\n",
       "      <td>580</td>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "      <td>166.56</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>353.52</td>\n",
       "      <td>0</td>\n",
       "      <td>4764966</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5236</td>\n",
       "      <td>7</td>\n",
       "      <td>904</td>\n",
       "      <td>1212</td>\n",
       "      <td>1515</td>\n",
       "      <td>26</td>\n",
       "      <td>816</td>\n",
       "      <td>220.08</td>\n",
       "      <td>0</td>\n",
       "      <td>5883894</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>22.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1029</td>\n",
       "      <td>7</td>\n",
       "      <td>3216</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var6 Var7 Var13 Var21 Var22 Var24 Var25   Var28 Var35    Var38  ...  \\\n",
       "0  1526    7   184   464   580    14   128  166.56     0     3570  ...   \n",
       "1   525    0     0   168   210     2    24  353.52     0  4764966  ...   \n",
       "2  5236    7   904  1212  1515    26   816  220.08     0  5883894  ...   \n",
       "3   NaN    0     0   NaN     0   NaN     0   22.08     0        0  ...   \n",
       "4  1029    7  3216    64    80     4    64     200     0        0  ...   \n",
       "\n",
       "  Var186_na  Var187_na Var188_na Var190_na  Var191_na Var209_na Var213_na  \\\n",
       "0     False      False     False     False      False     False     False   \n",
       "1     False      False     False     False      False     False     False   \n",
       "2     False      False     False     False      False     False     False   \n",
       "3     False      False     False     False      False     False     False   \n",
       "4     False      False     False     False      False     False     False   \n",
       "\n",
       "  Var215_na Var224_na Var230_na  \n",
       "0     False     False     False  \n",
       "1     False     False     False  \n",
       "2     False     False     False  \n",
       "3     False     False     False  \n",
       "4     False     False     False  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, i in zip(data_clean.columns,data_clean.dtypes):\n",
    "    if i == object:\n",
    "        try:\n",
    "            data_clean[col] = data_clean[col].astype(float)\n",
    "        except:\n",
    "            pass\n",
    "str_cols = []\n",
    "for col in data_clean.columns:\n",
    "    for i in range(len(data_clean)):\n",
    "        if pd.isna(data_clean[col].values[i]) == False:\n",
    "            if(type(data_clean[col].values[i])==str):\n",
    "                str_cols.append(col)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_occurency(a):\n",
    "    '''this function returns the most frequent element \n",
    "    in the given iterable element, while NaN values are ignored.\n",
    "    '''\n",
    "    freq_dict = {}\n",
    "    for elem in a:\n",
    "        if pd.isna(elem) == False:\n",
    "            if freq_dict.get(elem) == None:\n",
    "                freq_dict[elem] = 1\n",
    "            else:\n",
    "                freq_dict[elem] += 1\n",
    "    return max(freq_dict, key=freq_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_occurency(a):\n",
    "    freq_dict = {}\n",
    "    for elem in a:\n",
    "        if freq_dict.get(elem) == None:\n",
    "            freq_dict[elem] = 1\n",
    "        else:\n",
    "            freq_dict[elem] += 1\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply here function max_occurency to string columns in order to fill NaNs with most frequent value in the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in str_cols:\n",
    "    string_freq = max_occurency(data_clean[col].values)\n",
    "    data_clean[col].fillna(string_freq, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dicts = []\n",
    "for col in str_cols:\n",
    "    freq_dicts.append(freq_occurency(data_clean[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequent_strs = []\n",
    "for dictionary in freq_dicts:\n",
    "    strs = sorted(dictionary.items(), key=operator.itemgetter(1),reverse=True)[:3]\n",
    "    #print(strs)\n",
    "    frequent_strs.append(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used for decreasing the number of distinct string values. Here only most frequent values are kept, while other values are set to -1. After that we can either proceed one-hot encoding to them or just simply leave them as they are \n",
    "$(vals \\in{-1,0,1,2})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_repl_dict(freq_dict,i):\n",
    "    try:\n",
    "        repl_dict = [freq_dict[i][0][0],\n",
    "                 freq_dict[i][1][0],\n",
    "                 freq_dict[i][2][0]]\n",
    "        repl_set = {freq_dict[i][0][0],\n",
    "                freq_dict[i][1][0],\n",
    "                freq_dict[i][2][0]}\n",
    "    except:\n",
    "        repl_dict = [freq_dict[i][0][0],\n",
    "                 freq_dict[i][1][0]]\n",
    "        repl_set = {freq_dict[i][0][0],\n",
    "                freq_dict[i][1][0]}\n",
    "    return repl_dict, repl_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply our function to the data keeping in mind that exceptions may occur (if number of unique values is less than 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/egor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/egor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(str_cols)):\n",
    "    r_array, r_set = prepare_repl_dict(frequent_strs,i)\n",
    "    data_clean[str_cols[i]][data_clean[str_cols[i]].isin(r_set) == False] = -1\n",
    "    try:\n",
    "        for j in range(3):\n",
    "            data_clean[str_cols[i]][data_clean[str_cols[i]] == r_array[j]] = j\n",
    "    except:\n",
    "        for j in range(2):\n",
    "            data_clean[str_cols[i]][data_clean[str_cols[i]] == r_array[j]] = j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here and below we fill NaNs of numerical columns with corresponding median values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egor/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:3405: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_clean = data_clean.astype(float)\n",
    "for col in data_clean.columns:\n",
    "    med = np.ceil(np.median(data_clean[col].values))\n",
    "    data_clean[col].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_clean.columns:\n",
    "    data_clean[col]=data_clean[col].fillna(np.ceil(np.median(data_clean[col][data_clean[col].isna()==False].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure that we don't have any NaNs left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_clean.count():\n",
    "    assert i ==50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean[str_cols] = data_clean[str_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_curve, roc_auc_score, \n",
    "        accuracy_score, precision_score, recall_score, \n",
    "                             precision_recall_curve, average_precision_score, \n",
    "                             f1_score, classification_report)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_clean.drop('CHURN',axis=1).values\n",
    "y = data_clean['CHURN'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, \n",
    "                                                    random_state = 50, \n",
    "                                                    test_size= 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply PCA to the data in order to reduce the dimensionality of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyScaling_pca(X,n):\n",
    "    scaler = StandardScaler()\n",
    "    X_new = scaler.fit_transform(X)\n",
    "    pca_decomp = PCA(n)\n",
    "    pca_decomp.fit_transform(X_new)\n",
    "    return pca_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = ApplyScaling_pca(X_train,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11722717, 0.07836554, 0.04786221, 0.03810838, 0.03456889,\n",
       "       0.02563729, 0.02525956, 0.02326545, 0.02069041, 0.02028294,\n",
       "       0.01863848, 0.01775834, 0.01606735, 0.01600419, 0.0156389 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that 15 components are slightly more than optimal, let's try to reduce the n_components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11722717, 0.07836554, 0.04786221, 0.03810837, 0.03456888,\n",
       "       0.02563516, 0.02525994, 0.02326105, 0.02067551, 0.02027106])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = ApplyScaling_pca(X_train,10)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
